{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akshattri/Anime/blob/main/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "GouJQZm7gh6q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "486ae8a5-9963-4406-9615-5eac3d451dd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "gWziWujVx10s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Define the root directory where the images are stored\n",
        "root_dir_1 = '/content/drive/MyDrive/Dataset/test/Grave of the Fireflies'\n",
        "root_dir_2 = '/content/drive/MyDrive/Dataset/test/I want to eat your Pancreas'\n",
        "root_dir_3 = '/content/drive/MyDrive/Dataset/test/Perfect Blue'\n",
        "root_dir_4 = '/content/drive/MyDrive/Dataset/test/Spirited Away'\n",
        "root_dir_5 = '/content/drive/MyDrive/Dataset/test/Weathering With You'\n",
        "root_dir_6 = '/content/drive/MyDrive/Dataset/test/Your Name'\n",
        "\n",
        "# Define a list to store the images and labels\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "# Define a function to process a directory recursively\n",
        "def process_directory(data_dir, label):\n",
        "  \n",
        "  # Loop through each file in the directory\n",
        "  for filename in os.listdir(data_dir):\n",
        "\n",
        "    # Get the full path of the file\n",
        "    file_path = os.path.join(data_dir, filename)\n",
        "\n",
        "    # Check if the path is a file or directory\n",
        "    if os.path.isfile(file_path):\n",
        "      # Process the file\n",
        "      img = cv2.imread(file_path)\n",
        "      img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "      img = cv2.resize(img, (256, 256))\n",
        "      img = cv2.normalize(img.astype('float'), None, 0.0, 1.0, cv2.NORM_MINMAX)\n",
        "      images.append(img)\n",
        "      labels.append(label)\n",
        "    elif os.path.isdir(file_path):\n",
        "      # Recursively process files in subdirectories\n",
        "      pass\n",
        "\n",
        "process_directory(root_dir_1,0)\n",
        "process_directory(root_dir_2,0)\n",
        "process_directory(root_dir_3,0)\n",
        "process_directory(root_dir_4,0)\n",
        "process_directory(root_dir_5,0)\n",
        "process_directory(root_dir_6,0)\n",
        "\n",
        "# Convert the image and label lists to numpy arrays\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Print the shape of the image and label arrays\n",
        "print('Image shape:', images.shape)\n",
        "print('Label shape:', labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkkX0tf0gupU",
        "outputId": "b85d9661-6367-45f9-e294-66033114dd08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image shape: (1605, 256, 256)\n",
            "Label shape: (1605,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Define the root directories where the images are stored\n",
        "root_dirs = ['/content/drive/MyDrive/Dataset/test/Grave of the Fireflies',\n",
        "             '/content/drive/MyDrive/Dataset/test/I want to eat your Pancreas',\n",
        "             '/content/drive/MyDrive/Dataset/test/Perfect Blue',\n",
        "             '/content/drive/MyDrive/Dataset/test/Spirited Away',\n",
        "             '/content/drive/MyDrive/Dataset/test/Weathering With You',\n",
        "             '/content/drive/MyDrive/Dataset/test/Your Name']\n",
        "\n",
        "# Define the directory where the processed images will be saved\n",
        "save_dir = '/content/drive/MyDrive/Dataset/images'\n",
        "\n",
        "# Define a function to process a directory recursively\n",
        "def process_directory(data_dir, label, save_dir):\n",
        "  \n",
        "  # Loop through each file in the directory\n",
        "  for filename in os.listdir(data_dir):\n",
        "\n",
        "    # Get the full path of the file\n",
        "    file_path = os.path.join(data_dir, filename)\n",
        "\n",
        "    # Check if the path is a file or directory\n",
        "    if os.path.isfile(file_path):\n",
        "      # Process the file\n",
        "      img = cv2.imread(file_path)\n",
        "      img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "      img = cv2.resize(img, (256, 256))\n",
        "      img = cv2.normalize(img.astype('float'), None, 0.0, 1.0, cv2.NORM_MINMAX)\n",
        "\n",
        "      # Save the processed image\n",
        "      save_path = os.path.join(save_dir, f'{filename.split(\".\")[0]}.jpg')\n",
        "      cv2.imwrite(save_path, img)\n",
        "\n",
        "    elif os.path.isdir(file_path):\n",
        "      # Recursively process files in subdirectories\n",
        "      pass\n",
        "\n",
        "# Process each root directory and save the images in the save_dir\n",
        "for i, root_dir in enumerate(root_dirs):\n",
        "  process_directory(root_dir, i, save_dir)\n",
        "\n",
        "# Print a message indicating the processing is done\n",
        "print(f\"All images processed and saved to {save_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G76810nNiBCN",
        "outputId": "2cea6006-792a-43c3-a459-ff8017960b12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All images processed and saved to /content/drive/MyDrive/Dataset/images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "ABxbhwybuN4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training, validation, and testing sets\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(images, labels, test_size=0.15, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.18, random_state=42)\n",
        "\n",
        "# Print the shape of the image and label arrays for each set\n",
        "print('Training set:', X_train.shape, y_train.shape)\n",
        "print('Validation set:', X_val.shape, y_val.shape)\n",
        "print('Testing set:', X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rw9lYlpVn6RU",
        "outputId": "23b2b570-20f3-4c7f-9c8b-474f788884e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: (1040, 256, 256) (1040,)\n",
            "Validation set: (229, 256, 256) (229,)\n",
            "Testing set: (224, 256, 256) (224,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define the root directory where the images are stored\n",
        "root_dir = '/content/drive/My Drive/images/death note anime images'\n",
        "\n",
        "# Define a list to store the images and labels\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "# Define a function to process a directory recursively\n",
        "def process_directory(data_dir, label):\n",
        "  \n",
        "  # Loop through each file in the directory\n",
        "  for filename in os.listdir(data_dir):\n",
        "\n",
        "    # Get the full path of the file\n",
        "    file_path = os.path.join(data_dir, filename)\n",
        "\n",
        "    # Check if the path is a file or directory\n",
        "    if os.path.isfile(file_path):\n",
        "      # Process the file\n",
        "      img = cv2.imread(file_path)\n",
        "      img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "      img = cv2.resize(img, (256, 256))\n",
        "      img = cv2.normalize(img.astype('float'), None, 0.0, 1.0, cv2.NORM_MINMAX)\n",
        "      images.append(img)\n",
        "      labels.append(label)\n",
        "    elif os.path.isdir(file_path):\n",
        "      # Recursively process files in subdirectories\n",
        "      pass\n",
        "\n",
        "process_directory(root_dir, 0)#call it 6 more times we don't have to add the training dataset\n",
        "\n",
        "# Convert the image and label lists to numpy arrays\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Split the data into training, validation, and testing sets\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(images, labels, test_size=0.15, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.18, random_state=42)\n",
        "\n",
        "# Print the shape of the image and label arrays for each set\n",
        "print('Training set:', X_train.shape, y_train.shape)\n",
        "print('Validation set:', X_val.shape, y_val.shape)\n",
        "print('Testing set:', X_test.shape, y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "INK7klNjjBbn",
        "outputId": "b0b62f6f-faf9-4cd7-aa39-826b89400479"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-4dfa33ca192e>\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mprocess_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#call it 6 more times we don't have to add the training dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Convert the image and label lists to numpy arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-4dfa33ca192e>\u001b[0m in \u001b[0;36mprocess_directory\u001b[0;34m(data_dir, label)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;31m# Loop through each file in the directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Get the full path of the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/images/death note anime images'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(X_train, batch_size=32,\n",
        "                                          shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(X_val, batch_size=32,\n",
        "                                          shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(X_test, batch_size=32,\n",
        "                                         shuffle=False)"
      ],
      "metadata": {
        "id": "-BjgcCddwGez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEAZtPpnyZuc",
        "outputId": "ed8c1ef4-c74b-4c25-dd8a-ea623b5e8ff6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x7f8b0e8710f0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "# transform is for processing the images.(torchvision)"
      ],
      "metadata": {
        "id": "sq7XIwbXyvpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)"
      ],
      "metadata": {
        "id": "FK0lIquFu-mY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cnn architecture\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__() # Super here is for calling the constructor of parent class\n",
        "        self.conv1 = nn.Conv2d(1040, 32, kernel_size=3, stride=1, padding=1) # 178 is for input channels (grayscale) (X_train) and 32 is for no of filters which is equal to number of output channels.\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=2,stride=2,padding=0)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
        "        self.fc1 = nn.Linear(64*64*64,256) # Recheck it again\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(256, 1)  # Update this line\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.relu1(out)\n",
        "        out = self.maxpool1(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.relu2(out)\n",
        "        out = self.maxpool2(out)\n",
        "        out = out.view(-1, 64*64*64)\n",
        "        out = self.fc1(out)\n",
        "        out = self.relu3(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "# Convert X_train to a float32 Tensor\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "\n",
        "# Create the model\n",
        "model = CNN()\n",
        "\n",
        "# Pass the input data through the model to obtain the output\n",
        "output = model(X_train_tensor)\n",
        "\n",
        "# Print the output tensor shape\n",
        "print(output.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-3-jC6Zzd2C",
        "outputId": "39c33715-7b21-46ca-b72e-3768cc633e8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-0bd17dda556e>:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_train = torch.tensor(X_train, dtype=torch.float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MJkmd1fowfbR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}